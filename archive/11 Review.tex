
Issei Fujishiro, Gunther Weber, and Daniel Weiskopf <vis18c@precisionconference.com>
Jun 6 (1 day ago)
to me 
   Translate message
Turn off for: English
Dear Chaoqing Xu -

We regret to inform you that we are unable to accept your VIS 2018 SciVis submission:

  1116 - Fiber Tract based Visual Analytics for Studying Neurodegenerative Diseases

The reviews are included below. This year, VIS 2018 SciVis had 128 submissions and we conditionally accepted 32, for a provisional acceptance rate of 25%.

There were many factors considered in evaluating the reviews. Although numerical scores are important, we also read reviewers’ comments and discussion closely to understand their reasons for the scores. We arrived at the final decision by balancing these points of view.

Many of the submissions that were not accepted present exciting work and ideas. We hope you will find the reviewers' comments informative, especially if you revise your paper for submission to next year's conference, an affiliate conference (e.g. IEEE PacificVis), IEEE TVCG, or elsewhere.

We particularly encourage such revision where submissions were positively received by reviewers, but the revisions required were deemed to be beyond the scope of the conference review cycle. If you address the issues raised and subsequently submit to TVCG or IEEE PacificVis, or if you resubmit to next year's conference, please make reference to your VIS 2018 SciVis submission and include a description of how you addressed the SciVis reviewers' comments. 

Please also consider submitting work that was received positively to the IEEE VIS 2018 SciVis Short Papers program, due June 13. For the first time, the 2018 IEEE SciVis Conference solicits submissions in this new short paper format. Short papers offer a new way to contribute recent results and preliminary work to the VIS conference, which may be especially valuable for younger researchers. For more information, see http://ieeevis.org/year/2018/info/call-participation/scivis-short-papers

Another option to still present your work to the VIS audience and get further feedback on your ideas, is the IEEE VIS 2018 posters program, due June 16.  For more information, see http://ieeevis.org/year/2018/info/call-participation/posters

We thank you for submitting your paper to VIS 2018 SciVis. We wish you the best in your endeavors and hope to see you at the conference. Please see the conference website for updates on this year's program - http://www.ieeevis.org/

Issei Fujishiro, Gunther Weber, and Daniel Weiskopf
IEEE VIS 2018 SciVis Papers Chairs


----------------------------------------------------------------

Reviewer 1 review

  Paper type

    Application

  Expertise

    Expert

  Overall Rating

    <b>2 - Reject</b><br/> The paper is not ready for publication in SciVis /
    TVCG.<br/>The work may have some value but the paper requires major revisions or
    additional work that are beyond the scope of the conference review cycle to meet
    the quality standard. Without this I am not going to be able to return a score of
    '4 - Accept'.

  Supplemental Materials

    Acceptable with minor revisions (specify revisions in The Review section)

  Justification

    The submission presents a coordinated multiple views system for the fiber tract
    based study of neurodegenerative diseases. State-of-the-art machine learning
    techniques, methods from statistics, traditional views from information
    visualization, and an advanced rendering of DTI fibers have been coupled for
    inspecting and classifying patient populations. The main strength of this
    submission is certainly in this coupling. Also, the cases studies indicate the
    usefulness of the system. Unfortunately, there are multiple serious weaknesses of
    the submission that I believe cannot be resolved within the short time frame of
    the second round. However, I strongly encourage the authors to revise their
    submission and resubmit it to the regular IEEE TVCG journal. Briefly, the main
    weaknesses are (more details in the review):

    1) The authors classify their submission as a system paper. Then, there are
    several requirements in the IEEE SciVis definition of a system paper that are not
    met by the submission.
    2) I would rather classify the submission as an application paper and also
    reviewed it accordingly. However again, there are major requirements in this
    definition that are not met by the submission.
    3) Many parts of the paper would strongly benefit for more detailed explanations
    and illustrations or at least references to the existing figures. In particular,
    without detailed knowledge in statistics and ML, some parts are really hard to
    follow and also, to reenact by the reader.
    4) It does not become 100% clear how the submission improves over existing tools. 
    5) It is not clear to me why the 3D renderings and the analysis of attributes
    along fibers are restricted to individual subjects. In a population study,
    subgroup "averages" would be very useful.
    6) It seems that some parts of the paper have been written in a rush. They suffer
    from many spelling errors. Another indication is that the supplemental material is
    not referenced in the submission and insufficiently described in the document
    itself.

  The Review

    The main strength of this submission is certainly in the coupling of state-of-the-
    art machine learning techniques, methods from statistics, traditional views from
    information visualization, and an advanced rendering of DTI fibers. Also, the
    cases studies indicate the usefulness of the system. Unfortunately, there are
    multiple serious weaknesses of the submission that I believe cannot be resolved
    within the short time frame of the second round:

    1) The authors classify their submission as a system paper. Then, there are
    several requirements in the IEEE SciVis definition of a system paper that are not
    met (http://ieeevis.org/year/2018/info/call-participation/scivis-paper-types): The
    submission does not explain design decisions (e.g., why are certain plots chosen
    over other alternatives?, why are the plots arranged in the way they are?), the
    implications for software / hardware structure, and it does not include a
    comparison with other systems.

    2) I would rather classify the submission as an application paper. However again,
    there are major requirements in this definition that are not met by the paper. The
    medical tasks are not explained in sufficient detail. The target group of users is
    not described. No requirement analysis has been conducted. An expert evaluation of
    the system is missing.

    3) Many parts of the paper, in particular, Section 3, would strongly benefit for
    more detailed explanations and illustrations or at least references to the
    existing figures. Without detailed knowledge in statistics and ML, some parts are
    really hard to follow and also, to reenact by the reader. Figure 1 is meant to
    illustrate Section 3 but its parts are never explicitly referenced in the text. An
    overview diagram of the workflow that is described in Section 3 would be very
    helpful.

    4) It does not become 100% clear how the submission improves over existing tools.
    This does not become clear from the related work part, which is a listing of the
    work without explaining which works were inspiring or became the basis of the own
    implementation. It neither becomes clear from the remaining submission since their
    is no comparison with other tools. I understand that this is difficult since many
    tools may not be freely available but a least some attempt should be made in
    comparing the tools based on their papers.

    5) It is not clear to me why the 3D renderings and the analysis of attributes
    along fiber tracts are restricted to individual subjects. In a population study,
    subgroup "averages" could be very useful. The work of O'Donnel et al. may provide
    a good starting point here: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2768362/.

    6) It seems that some parts of the paper have been written in a rush. They suffer
    from many spelling errors. Another indication is that the supplemental material is
    not referenced in the submission and insufficiently described in the document
    itself.

    Other issues:

    - abstract: "visual analytic system" -> "visual analytics system"  
    - abstract: "to overcome several challenges" -> give examples
    - abstract: "to rank statistical features, brain regions, ..." -> rank according
    to what and why should be briefly explained
    
    - abstract: "conduct several cases studies" -> "conduct several case studies" 
    - there are several statements in the first part of the intro that must be backed
    up b references, e.g., "These technologies have an important role..." and the
    sentence after this one.
   
    - intro: "meanful" -> "meaningful"?  
    - PD must be introduced as an abbreviation  
    - "it's" -> "its"
    - Section 2: "To explore analysis of neuroimage data..." 
    - ECoG must be introduced as an abbreviation  
    - Related work: Angelelli et al. have presented a similar system that must be
    reference here: Interactive Visual Analysis of Heterogeneous Cohort Study Data, P.
    Angelelli, S. Oeltze, C. Turkay, J. Haasz, E. Hodneland, A. Lundervold, A.
    Lundervold, B. Preim, H. Hauser, IEEE Computer Graphics and Applications, 34(5),
    pp. 70-82, 2014.
    - Implementation is very briefly described at the end of Section 3. From a system
    paper I expect more details here.
    - First paragraph of Section 3.1: From the description it remains unclear, how the
    authors arrive at 1,800 features and which features exactly the compute.
    
    - "We found that most of the statistical features...from a normal distribution" ->
    how exactly did the authors find out? 
    -  Figure 1: the individual parts in the figure should be numbered and the numbers
    should be referred to in the caption and the text.
    - Section 3.3: Very hard to follow without illustrating figures.
    - Figure 2 is not referenced in the text
    - Section 3.5: "When the user mouses..." means that the user is catching mice. I
    am not sure if it was the intention of the authors to say that ;) The user hovers
    the mouse over something, I guess.  
    - Section 4: Why were the fibers reduced to 500,000?

    - Section 5.3 has only one subsection and it looks to me as if Section 5.4 should
    actually be Section 5.3.2, right?

    - Caption of Figure 9: What do the authors mean by "patches"?

    - The explanation in Section 5.5 is too short to really understand what the
    authors would like to express.
    - Section 5.6: "Several previous works noted..." and "We also noted some works..."
    -> mention the works explicitly
   
    - supplemental material: not referenced in the paper; not explained properly since
    it remains unclear what the images are supposed to the the reader; the legends are
    not readable

  Summary Rating

    <b>Reject</b><br/> The paper is not ready for publication in SciVis /
    TVCG.<br/>The work may have some value but the paper requires major revisions or
    additional work that are beyond the scope of the conference review cycle to meet
    the quality standard. Without this I am not going to be able to return a score of
    '4 - Accept'.

  The Summary Review

    The submission presents a coordinated multiple views system for the fiber tract
    based study of neurodegenerative diseases. State-of-the-art machine learning
    techniques, methods from statistics, traditional views from information
    visualization, and an advanced rendering of DTI fibers have been coupled for
    inspecting and classifying patient populations. The main strength of the
    submission is certainly in this coupling allowing for an organized data analysis
    flow. All reviewers appreciate the effort that the authors have taken and see
    promising first steps. However, there are multiple serious weaknesses of the
    submission that the reviewers believe cannot be completely resolved within the
    short time frame of the second review cycle:

    1) The paper has been classified by the authors as systems paper but no
    explanation of design decisions, their implications for software / hardware
    structure, and comparison with other systems were provided.
    2) The reviewers rather considered the submission as an application paper but with
    a very vague problem focus and no evaluation by domain experts.
    3) It is not shown that the tool developed allows for findings that would not have
    been possible otherwise.
    4) The (medical) results that have been achieved with the system and their
    interpretation are questionable.
    5) The proposed framework suffers from serious statistical flaws.
    6) The spatial information is presented only for individuals but not for groups,
    which is questionable in cohort analysis.
    7) The authors provide several algorithms for solving a single problem, e.g.,
    dimensionality reduction algorithms, but it is not clear which one is working
    better.
    8) A video illustrating the interactive aspects of the tool is missing.

    More details on each point are given in the individual reviews.

  Second round comments (public)

    (blank)

  Second round supplementary materials check

    (blank)

  Second round supplementary materials comments

    (blank)

----------------------------------------------------------------

Reviewer 2 review

  Paper type

    System

  Expertise

    No or passing knowledge

  Overall Rating

    <b>2.5 - Between Reject and Possible Accept</b><br/>

  Supplemental Materials

    Not acceptable

  Justification

    The paper presents a system for the visual exploration of patients with Parkinson
    disease. The strong points are that the system is promising, and incorporates a
    lot of potentially useful features.
    On the other hand, the way it is presented through the paper makes it seem not
    mature. The authors do not mention domain experts' intervention in the definition
    of features as well as in the evaluation of the outcomes. All in all, I have the
    feeling that the authors did their best to add the functions that they sincerely
    believe that are going to be useful, and they did it properly. Unfortunately,
    without the help of a domain expert that guides them into the integration, the
    utility can not be properly assessed.

  The Review

    The paper is in general properly written and I believe that most of the important
    literature is there, although, since I cannot claim myself an expert, I am not
    sure. On some areas, I found some references that might be important citing, and
    are mentioned later in this review.

    Several aspects need more detail or justification:

    The authors use “the brain functional regions to group the fibers for pairwise
    statistical comparison”, but do not mention how accurate is this with the
    different models, e.g. might this lead to errors, if so, how important are those.
    Nonetheless, I imagine that, should this classification be wrong, it might skew
    the learning algorithms later.

    I also do not understand why the authors use one-way f-test for classifier
    accuracy evaluation in Figure 2 when they stated that it assumes normality, which
    is not guaranteed.

    It is difficult to evaluate if the feature selection chosen is the most adequate
    or not. Several papers have previously addressed a similar problem, for instance:
    “SVM feature selection based rotation forest ensemble classifiers to improve
    computer-aided diagnosis of Parkinson disease”, by Ozcift, 2012.
    Also a set of works by Haller et al. seem to overlap this part, such as
    “Individual detection of patients with Parkinson disease using support vector
    machine analysis of diffusion tensor imaging data: initial results”, and
    “Differentiation between Parkinson disease and other forms of Parkinsonism using
    support vector machine analysis of susceptibility-weighted imaging (SWI): initial
    results”. I am not suggesting that these papers are better, since I am not an
    expert in ML, but they should be considered, since this part of the paper, may be
    worth a publication by itself, if sound enough, which is not evaluated anywhere in
    the rest of the paper. Of course, the authors may select a suboptimal technique to
    demonstrate their contribution, which is the visual analytics system, but for the
    non-experts, they should position their steps so that we can understand how far or
    close they may be of a real diagnosing system.

    The authors provide several dimensionality reduction algorithms, but it is not
    clear which one is working better.
    They mention that all of them seem to work well to separate two groups, but, by
    observing the different plots, it seems that the performance varies a lot,
    especially the TSNE seems to do an inferior work on the values. Moreover, the
    perplexity seems to be not selectable, which, as known, may affect the outcome
    greatly. The impression one gets is that they incorporated everything which was
    available in the scikit library and let the user choose. That is not what a
    physician will like to do, they will expect some guidance.


    Overall application

    My most important concern is that the utility of the application is not clearly
    demonstrated through a user study or the opinion of domain experts. I think the
    authors did a great effort and probably the application is really close to be of
    use, but there are many design decisions and features whose incorporation is not
    properly justified.

    For instance, the overall distribution of the application is not backed by some
    general conception or previous literature. The rendering occupies a major part of
    the screen, while most of the analysis, that I understand guides the exploration,
    receives just a small portion.

    Why the details appear up front? There are at least three data tables that need to
    be scrolled a lot to see the information. Some overview would be required for the
    rightmost, and probably useful for the rest. Unless some important reason is
    preventing the authors to design the application under the well-known
    visualization mantra (overview first, zoom and filter, details on demand), I do
    not see why the whole bunch of information should be presented in the same view.
    This makes the main view too large, and when the authors try to show it, they use
    a Figure that results too small to see the details. Figure 1 is too small to be
    seen without zooming. In a printed version I was unable to distinguish most of the
    contents. Even with the PDF, a 200% amplification still renders some of the texts
    too difficult to be read.


    Summary

    I believe that there is a lot of work done in the right direction, but the authors
    clearly need to focus the application and find use cases of utility. The analysis
    of most of the use cases has the form "several cases were confirming our
    hypothesis, but some healthy cases also behaved the same way". It is another clear
    example that they require the input from a domain expert to properly evaluate
    their results and potential usefulness of their application.

    The supplemental material is clearly lacking. There are mainly images of a certain
    case, without further analysis. I would have expected a video of the working
    application, maybe showing the workflow of a full use case.

    Finally, some of the conclusions are somewhat confusing: the authors say that it
    would be interesting to have more cases, but the processing time is expensive
    (???). Of course it is, but if they want to have more reliable data, it might be
    necessary. I understand the costs that it might represent, but the problem the
    authors tackle is really important and with potential for helping a lot of people
    and the effort is worth it.



    Typos and minor issues:

    Saxon genitive is used wrong many times, e.g. the authors write “persons brain”
    many times, instead of “person’s brain”
    Figure 2 has a legend where Kernal instead of Kernel is written.
    Also, in the legend, Kneighbors -> Neighbors

    It is the first time I read “mouses” instead of “hovers”
    Section 3.4 has only a subsection, it would be better to have none or two. The
    same happens for 5.3.
    Some other small typos are there (e.g. registraion, seamed -> seemed, this one
    several times)


----------------------------------------------------------------

Reviewer 3 review

  Paper type

    Application

  Expertise

    Expert

  Overall Rating

    <b>1.5 - Between Strong Reject and Reject</b><br/>

  Supplemental Materials

    Not acceptable

  Justification

    This manuscript has the following strengths:

     - It deals with an important and challenging application, i.e., studying
    neurodegenerative diseases with diffusion tensor imaging.

     - It combines predictive modeling with visualization.

    Despite these points, for the following reasons, I strongly feel that the paper in
    its current form should not appear at SciVis 2018:

     - The proposed framework suffers from serious statistical flaws.

     - Evaluation did not appear to involve any domain experts.

     - The current results that have been achieved with the system and their
    interpretation are questionable.

    Details on each of these points are given in the review below.

  The Review

    Statistical flaws:
    ------------------

    One of the main goals of the proposed system is predictive modeling, i.e., it
    allows the user to build classifiers that tell apart patients from healthy
    controls based on the DTI data. Unfortunately, the proposed visual analytics
    system provides mechanisms for pre-selecting features based on their statistical
    significance on the full dataset. This can lead to - potentially strongly -
    inflated estimates of classification accuracy, which will prove to be unrealistic
    when the classifier is applied to unseen data. This is particularly harmful given
    that the cross validation process employed later on might give the misleading
    impression of "avoiding bias and over fitting in the model training and prediction
    process" and to "prevent the user from concluding that a given prediction or model
    performance is more reliable than it actually is", as it is explicitly claimed on
    p.4.

    The statistical bias comes from the fact that features are selected on the basis
    of statistical tests that have been performed on the full dataset, outside of the
    cross-validation. This might seem like a minor detail, but given that the
    candidate set of features (about 1800) is large relative to the number of subjects
    (120), it is likely to contain subsets that could be used to predict, with
    seemingly high accuracy, almost any labels, even random or meaningless ones. The
    fact that a statistical test can identify them does unfortunately not guarantee a
    successful classification of unseen data.

    Resolving this issue would require changing the design of the visual analytics
    system so that it evaluates classifier accuracy on a dedicated held-out test set,
    rather than with cross-validation. The test set may not be used for feature
    selection and, in fact, should not be visible to the user at any point while
    tuning the classifier with the visual analytics system. All experiments would have
    to be repeated with the modified system, and the set of features selected
    previously should not be available in the re-analysis - ideally, it would be
    performed by a different operator who is blinded to the previous result, or a
    different data set would be chosen.

    Evaluation:
    -----------

    The authors present a "case study" based on data from the Parkinson's Progression
    Markers Initiative, but as far as I could tell from the manuscript, no domain
    experts were involved in it, so it should better be referred to as a "usage
    scenario".

    Feedback from domain experts would also be required to convince me that certain
    design decisions - such as giving the user a free choice of six different methods
    for dimensionality reduction, without any further guidance - are indeed helpful
    for the intended target group of medical researchers. I fear that they might
    rather lead to confusion.

    Results:
    --------

    The analysis performed with the system led to three main results (5.4.1, 5.4.2,
    5.5), two of which are observations of differences in "raw T2 signal". This is
    problematic, since raw T2 signal intensity from standard MR sequences is not
    calibrated, i.e., it is expected to vary between scanners and even between re-
    scans of the same subject on the same scanner. This makes conclusions drawn from
    between-subject differences in it highly questionable. The authors do not offer
    any plausible anatomical interpretation of their observations. In fact, vague and
    imprecise observations such as "This characteristic seamed more prevalent in the
    disease group, yet is also found in many control group subjects as well." (caption
    of Fig. 9) are compatible with the null hypothesis that the authors essentially
    examined random fluctuations.

    The observation in 5.4.1, i.e., that the number and total length of streamlines
    from fiber tractography correlates with the disease, is plausible. However, it
    should not be interpreted in terms of "fiber loss". Even though a visualization
    such as Fig. 7 might strongly suggest it, the corresponding tracts are not
    actually absent in the patients - the employed tractography method merely failed
    to reconstruct them, most probably due to pathological changes in diffusion
    properties that affected the termination criteria of the tracking algorithm. More
    care has to be taken to provide a correct interpretation of such findings. The
    following reference should be helpful for this

    D.K. Jones: Challenges and limitations of quantifying brain connectivity in vivo
    with diffusion MRI. Imaging Med. 2010; 2:341-355

    Other comments:
    ---------------

    In Section 3, the authors state that "constructing unbiased sets of pairwise
    comparable bundles is still challenging". It certainly is, but it should be
    mentioned that there is now more than a decade of literature that tackles this
    challenge, such as

    Corouge et al. Fiber tract-oriented statistics for quantitative diffusion tensor
    MRI analysis. Medical Image Analysis 10:786-798, 2006

    Yushkevich et al. Structure-specific statistical mapping of white matter tracts.
    NeuroImage 41:448-461, 2008

    O'Donnell et al. Tract-based morphometry for white matter group analysis.
    NeuroImage 45:832-844, 2009

    along with many more recent works.

    Similarly, the two references chosen to represent predictive modeling of DTI data
    in the related work section [3,6] are not the only, earliest, or most influential
    examples.

    I find it difficult to fully judge a highly interactive visual analytics system
    like this without a supplemental video that demonstrates it. Instead, the current
    supplement consists of a PDF that includes a large number of screenshots with very
    little explanation, which I found to be of limited use.

    The manuscript still contains a large number of typos such as "neurodenerative",
    "reproductin", "kernalized", "seamed", "difusion", "distibution", etc.
    %% fixed
----------------------------------------------------------------

Reviewer 4 review

  Paper type

    System

  Expertise

    Expert

  Overall Rating

    <b>4 - Accept</b><br/> The paper should be accepted with some minor
    revisions.<br/>Once these have been completed it will meet the quality standard.

  Supplemental Materials

    Acceptable

  Justification

    see review

  The Review

    This paper presents an integrative approach for neuroscience research that wish to
    analyze a cohort of diffusion tensor imaging (DTI) patient and control data of a
    certain neurodegenerative disease, here Parkinson's disease.
    Through an organized data analysis flow, established machine learning techniques
    can be easily applied to the data, and outcomes can be interactively inspected
    using insightful graphs. Fiber tract visualizations add in interpreting the
    statistical outcomes.

    The data presentation is clear.

    Coming from the application domain, this paper raises a few questions.

    An interactive interface encourages researchers to perform iterative and
    repetitive analyses until an optimized outcome (e.g. classification score, AUC) is
    found. This approach can be called an interactive model selection procedure and is
    a strength of this work. A weakness is that this is also prone to overfitting,
    because of repeated cross-validations. It remains the researchers' responsibility
    to analyze a hold-out dataset after the classification procedure is optimized. Is
    such a step supported by this work?

    The tractography visualizations are taking a prominent place in the system and
    figure papers, but are perhaps not the most important display from an application
    perspective. The graphs in Fig. 4 are most insightful and deserve more 'physical'
    space in the system.

    The trackings do not represent known fibre bundles. Have the authors considered
    adding cross-sections / 2D slices for anatomical context?

    The substantia nigra is a gray matter region and not part of a fibre bundle. The
    fact that the raw T2 signal is most discriminant is certainly interesting, caused
    by iron accumulation in this nucleus. This can be seen in T2- or T2*-weighted
    images. DTI is not the first choice of modality. Or do the results show fibres
    departing from this brain region?

    %% paper: Brain iron homeostasis and neurodegenerative disease.

    Revisions required
    ==============

    Please address the abovementioned questions in the Discussion section.

----------------------------------------------------------------

Reviewer 5 review

  Paper type

    Application

  Expertise

    Expert

  Overall Rating

    <b>2 - Reject</b><br/> The paper is not ready for publication in SciVis /
    TVCG.<br/>The work may have some value but the paper requires major revisions or
    additional work that are beyond the scope of the conference review cycle to meet
    the quality standard. Without this I am not going to be able to return a score of
    '4 - Accept'.

  Supplemental Materials

    Acceptable with minor revisions (specify revisions in The Review section)

  Justification

    This paper has been given as a system paper. I would think it is rather an
    application paper since the software and hardware structure are not described
    neither the main focus of this paper. Rather the description of a visual analytics
    solution for a specific problem.
    However, the paper reads a lot like a specific study describing a tool that was
    build for the study. I think the focus of this paper is very vague and it makes it
    difficult to find out what is a clear contribution.
    From my point of view the findings themselves of the study cannot be a
    contribution to  SciVis, what would be a contribution is to show that the tool
    developed allowed for findings that would not have been possible otherwise.

    Design choices are not discussed extensively. Why this visual encodings or
    interactions? why not others? and then show whether they work or not. At this
    point this paper is not doing that is rather presenting what was used without
    argumentation. The choices are similar to other existing systems that are used for
    the analysis of ML classification or feature spaces so it is unclear what is
    different on what they propose. There is no comparison to these systems...

    What is specific to DTI fiber tracts? 
    The spacial information is shown by individual and just showing the tracts
    themselves  with color-coded properties (also shadowing has been used before)...
    so there is no major contribution there for the fact that we are addressing
    groups, as far as I can evaluate. I think a lot could be done there since it is
    definitely challenging to show this spatial information for groups of brains and
    even more to show the differences between groups.

    The paper is addressing an important problem where Visual Analysis can have an
    important contribution. I believe the paper presents some of this ideas but they
    are addressing them in a rather standard and straight forward way.
    In its current form the contribution to the Visualization literature is very
    limited and I would not consider it acceptable for publication without a major
    revision.

  The Review

    The title is too specific. I think the software presented could be used not just
    for the study of Neurodegenerative diseases but actually any DWI brain group
    studies.
    The focus is on the SN but there is no specific feature that would avoid to use it
    in other structures, and similar goals appear in any neuroscicence group study, so
    maybe a broader spectrum when looking at the problem would help.

    The paper is clear and well writen from the language point of view.

    The authors build a complex pipeline, including feature extraction,  which is
    similar to other pipelines in neuroscience, I do not think there is a specific
    contribution there. It is rather a preprocessing needed to have the data to the
    visual analysis system. This is needed but it is not a contribution and I think
    that authors could also strenghten the paper by making clear the scope of their
    visual analysis design. In my opinion, it starts with a feature space generated
    from on fiber tracking on DTI data and the corresponding fiber tracts.
    If the feature ranking itself is novel or the pipeline this should be more clearly
    given.

    I think the authors should do a better effort analyzing and abstracting the
    tasks/data that the users want to do, building an structured analysis. Also use
    this abstraction to define and motivate their design. Right now it is rather a
    description of what is there but not an structured design and motivation of why.
    This would help to make the paper more interesting for the IEEE Vis community in
    general.
    Some examples... why do you show the data you show? why this specific ranking (is
    there a difference to others?)? why is a list the best way to show the ranked
    features? why side by side comparison of the tracts of individuals is the best way
    to get spatial information? are there no better options superposition,
    differences?  Why using point by point rendering at the scatterplot it generates
    occlusion, figure 8 illustrates that.


    I also think the authors should focus on the difference to other existing systems
    for feature space analysis, which is currently missing in the related work.
    For example http://fodava.gatech.edu/fodava-testbed-software 
    Krause, Josua, Adam Perer, and Enrico Bertini. "INFUSE: interactive feature
    selection for predictive modeling of high dimensional data." IEEE transactions on
    visualization and computer graphics 20, no. 12 (2014): 1614-1623.

    This are not per se the most similar papers but authors should make an effort to
    compare to those and make clear what are the differences. In essence they propose
    feature space analysis for a spaceific application, but it is unclear what is
    specific or different from other systems.

    There related work is rather showing current neurosciene tools but there is more
    than that in literature.
    DTI literature is very broad, I think the visualization of DTI itself is not so
    interesting for this paper and it is presented in a rather adhoc/incomplete form
    given its broadness. There are reviews on DTI visualization that might be better
    referenced here. For this paper but rather group based analysis from which there
    is a limited literature would be of interest.

    For example:
    Abbasloo, Amin, Vitalis Wiens, Max Hermann, and Thomas Schultz. "Visualizing
    tensor normal distributions at multiple levels of detail." IEEE transactions on
    visualization and computer graphics 22, no. 1 (2016): 975-984.
    and other articles in which summarization of groups and comparison of DTI data
    sets are the focus. There are few of those.

    I think an important challenge is to show the group analysis from which there are
    no obvious solutions. Also work on uncertaintly seems relevant to me.

    Also the standard general classification analysis of ROC FP,TP,FN, TN is not per
    se a contribution. What is being added that makes the paper different?
    How interactive is this part? It seems it is based on the selected features this
    would be interesting but for the rest it is rather standard.
    Similarly with the dimensionality reduction methods how interactive are those?

    It is unclear to me what is being achieved by showing the spatial data... It is
    mentioned it is important but not why.  I do believe it can be important but the
    authors should give better argumentation.

    Are the color maps normalized by dataset? this might bias the comparison... and
    conclusions from case studies
    Some of the features have a direct meaning for the user, so the information shown
    to the user should not be normalized, the real value should be given.
    Case studies should focus more on the features of the system that allow an
    analysis that would not be possible otherwise.

    There are some typos here and there that would require revision.
    You need to define n in section 3.2
    I also miss a video illustrating the proposed software.

----------------------------------------------------------------


	
Click here to Reply or Forward
2.06 GB (13%) of 15 GB used
Manage
Terms - Privacy
Last account activity: 30 minutes ago
Details

